use std::collections::{HashMap, HashSet};
use std::fs;
use std::path::{Path, PathBuf};

use chrono::Utc;
use tracing::{debug, info};

use crate::config::{Config, CrateDoc};
use crate::error::{AiDocsError, Result};
use crate::fetcher::github::{FetchedFile, ResolvedRef};
use crate::processor::changelog;

const META_SCHEMA_VERSION: u32 = 2;

#[derive(serde::Serialize, serde::Deserialize, Debug)]
pub struct CrateMeta {
    #[serde(default)]
    pub schema_version: u32,
    pub version: String,
    pub git_ref: String,
    pub fetched_at: String,
    pub is_fallback: bool,
    #[serde(default)]
    pub config_hash: Option<String>, // Renamed from config_fingerprint
    #[serde(default)]
    pub source_kind: Option<String>,
    #[serde(default)]
    pub artifact_path: Option<String>,
    #[serde(default)]
    pub docsrs_input_url: Option<String>,
    #[serde(default)]
    pub docsrs_canonical_base_url: Option<String>,
    #[serde(default)]
    pub upstream_latest_version: Option<String>,
    #[serde(default)]
    pub upstream_checked_at: Option<String>,
    #[serde(default)]
    pub ttl_expires_at: Option<String>,
    #[serde(default)]
    pub truncated: Option<bool>,
    #[serde(default)]
    pub truncation_marker: Option<String>,
    #[serde(default)]
    pub artifact_sha256: Option<String>,
    #[serde(default)]
    pub artifact_bytes: Option<usize>,
}

#[derive(Debug, Clone)]
pub struct SavedCrate {
    pub name: String,
    pub version: String,
    pub git_ref: String,
    pub is_fallback: bool,
    pub files: Vec<String>,
    pub ai_notes: String,
}

// crate_config_fingerprint removed in favor of CrateDoc::config_hash

fn render_crate_summary(saved: &SavedCrate) -> String {
    render_summary_with_provenance(saved, None)
}

fn render_summary_with_provenance(saved: &SavedCrate, provenance: Option<&str>) -> String {
    let mut content = String::new();
    content.push_str("<!-- This file is auto-generated by ai-fdocs. Do not edit manually. -->\n\n");

    if saved.is_fallback {
        content.push_str(&format!("# {}@{} âš ï¸\n\n", saved.name, saved.version));
        content.push_str(&format!(
            "Fetched from `{}` because no exact release tag was found for `{}`.\n\n",
            saved.git_ref, saved.version
        ));
    } else {
        content.push_str(&format!("# {}@{}\n\n", saved.name, saved.version));
    }

    if let Some(provenance) = provenance {
        content.push_str(&format!("## Source\n\n{}\n\n", provenance.trim()));
    }

    if !saved.ai_notes.trim().is_empty() {
        content.push_str(&format!("## AI Notes\n\n{}\n\n", saved.ai_notes.trim()));
    }

    content.push_str("## Files\n\n");
    if saved.files.is_empty() {
        content.push_str("- _No fetched files._\n");
    } else {
        for file in &saved.files {
            content.push_str(&format!("- [{}]({})\n", file, file));
        }
    }

    content
}

fn latest_docs_summary_provenance(
    source_kind: &str,
    docsrs_input_url: &str,
    truncated: bool,
) -> String {
    let mut lines = Vec::new();
    match source_kind {
        "docsrs" => lines.push(format!("- Source kind: `docsrs` ({docsrs_input_url})")),
        "github_fallback" => lines.push(format!(
            "- Source kind: `github_fallback` (docs.rs unavailable: {docsrs_input_url})"
        )),
        other => lines.push(format!("- Source kind: `{other}`")),
    }

    lines.push(format!("- Truncated: `{truncated}`"));
    lines.join("\n")
}

pub fn flatten_filename(file_path: &str) -> String {
    if file_path.contains('/') {
        file_path.replace('/', "__")
    } else {
        file_path.to_string()
    }
}

fn inject_header(
    content: &str,
    owner_repo: &str,
    git_ref: &str,
    original_path: &str,
    is_fallback: bool,
    version: &str,
    source_url: &str,
) -> String {
    let date = Utc::now().format("%Y-%m-%d").to_string();
    let mut header = format!(
        "<!-- AI-FDOCS: source=github.com/{owner_repo} ref={git_ref} path={original_path} fetched={date} -->\n<!-- AI-FDOCS: url={source_url} -->\n"
    );

    if is_fallback {
        header.push_str(&format!(
            "<!-- AI-FDOCS WARNING: No tag found for version {version}. Fetched from '{git_ref}' branch. Content may not match installed version. -->\n"
        ));
    }

    format!("{header}\n{content}")
}

fn should_inject_header(file_path: &str) -> bool {
    let path = std::path::Path::new(file_path);
    path.extension().is_some_and(|ext| {
        ext.eq_ignore_ascii_case("md")
            || ext.eq_ignore_ascii_case("html")
            || ext.eq_ignore_ascii_case("htm")
    })
}

pub fn truncate_if_needed(content: &str, max_size_kb: usize) -> (String, bool) {
    let max_bytes = max_size_kb * 1024;
    if content.len() <= max_bytes {
        return (content.to_string(), false);
    }

    let boundary = crate::utils::floor_char_boundary(content, max_bytes);
    let truncated = &content[..boundary];
    (
        format!("{truncated}\n\n[TRUNCATED by ai-fdocs at {max_size_kb}KB]\n"),
        true,
    )
}

fn load_meta_with_migration(meta_path: &Path) -> Option<CrateMeta> {
    let content = fs::read_to_string(meta_path).ok()?;
    let mut meta: CrateMeta = toml::from_str(&content).ok()?;

    if meta.schema_version < META_SCHEMA_VERSION {
        // Auto-migrate if needed, but for hash check we might just invalidate if hash is missing.
        // For now, allow reading old meta, but is_cached will fail if hash is missing/mismatch.
        // We don't strictly need to write back immediately unless we have new data.
        // But let's treat it as valid structure.
    }

    if meta.schema_version > META_SCHEMA_VERSION {
        return None;
    }

    Some(meta)
}

fn save_meta(meta_path: &Path, meta: &CrateMeta) -> Result<()> {
    let meta_content = toml::to_string_pretty(meta)
        .map_err(|e| AiDocsError::Other(format!("Failed to serialize meta: {e}")))?;
    fs::write(meta_path, meta_content)?;
    Ok(())
}

pub fn is_cached(
    output_dir: &Path,
    crate_name: &str,
    version: &str,
    crate_config: &CrateDoc,
) -> bool {
    let crate_dir = output_dir.join(format!("{crate_name}@{version}"));
    let meta_path = crate_dir.join(".aifd-meta.toml");

    if !meta_path.exists() {
        return false;
    }

    match load_meta_with_migration(&meta_path) {
        Some(meta) => {
            let current_hash = crate_config.config_hash();
            if meta.version != version {
                return false;
            }
            // Check config hash (new v2 way)
            if let Some(cached_hash) = &meta.config_hash {
                return cached_hash == &current_hash;
            }

            // Fallback for v1 (optional): if strict, return false.
            // If we want to force upgrade to v2, return false.
            false
        }
        None => false,
    }
}

pub struct SaveRequest<'a> {
    pub crate_name: &'a str,
    pub version: &'a str,
    pub fetched_files: &'a [FetchedFile],
    pub crate_config: &'a CrateDoc,
}

pub fn save_crate_files(
    output_dir: &Path,
    save_ctx: &SaveContext<'_>,
    req: SaveRequest<'_>,
) -> Result<SavedCrate> {
    let crate_dir = output_dir.join(format!("{}@{}", req.crate_name, req.version));

    if crate_dir.exists() {
        fs::remove_dir_all(&crate_dir)?;
    }
    fs::create_dir_all(&crate_dir)?;

    let mut saved_names = Vec::new();

    let mut total_bytes = 0;
    let mut any_truncated = false;

    // For GitHub we don't have a single artifact but multiple files.
    // We'll calculate a combined SHA256 of all file contents for consistency.
    use sha2::{Digest, Sha256};
    let mut hasher = Sha256::new();

    for file in req.fetched_files {
        let flat_name = flatten_filename(&file.path);
        let mut content = file.content.clone();

        if file.path.to_lowercase().contains("changelog") {
            content = changelog::truncate_changelog(&content, req.version);
        }

        let (truncated_content, is_truncated) =
            truncate_if_needed(&content, save_ctx.max_file_size_kb);
        content = truncated_content;
        if is_truncated {
            any_truncated = true;
        }

        if should_inject_header(&file.path) {
            content = inject_header(
                &content,
                save_ctx.repo,
                &save_ctx.resolved.git_ref,
                &file.path,
                save_ctx.resolved.is_fallback,
                req.version,
                &file.source_url,
            );
        }

        let file_path = crate_dir.join(&flat_name);
        let content_bytes = content.as_bytes();
        fs::write(&file_path, content_bytes)?;

        hasher.update(content_bytes);
        total_bytes += content_bytes.len();

        debug!("Saved: {:?}", file_path);
        saved_names.push(flat_name);
    }

    let artifact_sha256 = format!("{:x}", hasher.finalize());

    let meta = CrateMeta {
        schema_version: META_SCHEMA_VERSION,
        version: req.version.to_string(),
        git_ref: save_ctx.resolved.git_ref.clone(),
        fetched_at: Utc::now().format("%Y-%m-%d").to_string(),
        is_fallback: save_ctx.resolved.is_fallback,
        config_hash: Some(req.crate_config.config_hash()),
        source_kind: Some(save_ctx.source_kind.to_string()),
        artifact_path: save_ctx.artifact_path.map(str::to_string),
        docsrs_input_url: save_ctx.docsrs_input_url.map(str::to_string),
        docsrs_canonical_base_url: None, // Will be filled when needed
        upstream_latest_version: save_ctx.upstream_latest_version.map(str::to_string),
        upstream_checked_at: Some(Utc::now().format("%Y-%m-%d").to_string()),
        ttl_expires_at: None, // Calculated by orchestrator
        truncated: Some(any_truncated),
        truncation_marker: if any_truncated {
            Some(format!(
                "[TRUNCATED by ai-fdocs at {}KB]",
                save_ctx.max_file_size_kb
            ))
        } else {
            None
        },
        artifact_sha256: Some(artifact_sha256),
        artifact_bytes: Some(total_bytes),
    };

    save_meta(&crate_dir.join(".aifd-meta.toml"), &meta)?;

    info!(
        "  ðŸ’¾ {}@{}: {} files saved to {:?}",
        req.crate_name,
        req.version,
        saved_names.len(),
        crate_dir
    );

    let saved = SavedCrate {
        name: req.crate_name.to_string(),
        version: req.version.to_string(),
        git_ref: save_ctx.resolved.git_ref.clone(),
        is_fallback: save_ctx.resolved.is_fallback,
        files: saved_names,
        ai_notes: req.crate_config.ai_notes.clone(),
    };

    let provenance = if save_ctx.source_kind == "github_fallback" {
        Some(
            "- Source kind: `github_fallback`\n- Reason: docs.rs failed and GitHub fallback was used",
        )
    } else {
        None
    };

    fs::write(
        crate_dir.join("_SUMMARY.md"),
        render_summary_with_provenance(&saved, provenance),
    )?;

    Ok(saved)
}

pub fn save_latest_api_markdown(
    output_dir: &Path,
    crate_name: &str,
    version: &str,
    api_markdown: &str,
    docsrs_input_url: &str,
    truncated: bool,
    crate_config: &CrateDoc,
) -> Result<SavedCrate> {
    let crate_dir = output_dir.join(format!("{crate_name}@{version}"));

    if crate_dir.exists() {
        fs::remove_dir_all(&crate_dir)?;
    }
    fs::create_dir_all(&crate_dir)?;

    fs::write(crate_dir.join("API.md"), api_markdown)?;

    // Calculate SHA256
    use sha2::{Digest, Sha256};
    let mut hasher = Sha256::new();
    hasher.update(api_markdown.as_bytes());
    let sha256 = format!("{:x}", hasher.finalize());

    let meta = CrateMeta {
        schema_version: META_SCHEMA_VERSION,
        version: version.to_string(),
        git_ref: format!("docsrs/{version}"),
        fetched_at: Utc::now().format("%Y-%m-%d").to_string(),
        is_fallback: false,
        config_hash: Some(crate_config.config_hash()),
        source_kind: Some("docsrs".to_string()),
        artifact_path: Some("API.md".to_string()),
        docsrs_input_url: Some(docsrs_input_url.to_string()),
        docsrs_canonical_base_url: Some(format!("https://docs.rs/{crate_name}/{version}")),
        upstream_latest_version: Some(version.to_string()),
        upstream_checked_at: Some(Utc::now().format("%Y-%m-%d").to_string()),
        ttl_expires_at: None, // Default TTL handled by status logic
        truncated: Some(truncated),
        truncation_marker: if truncated {
            Some(format!(
                "[TRUNCATED by ai-fdocs at {}KB]",
                crate_config.max_file_size_kb
            ))
        } else {
            None
        }, // Fixed marker logic
        artifact_sha256: Some(sha256),
        artifact_bytes: Some(api_markdown.len()),
    };

    save_meta(&crate_dir.join(".aifd-meta.toml"), &meta)?;

    let saved = SavedCrate {
        name: crate_name.to_string(),
        version: version.to_string(),
        git_ref: format!("docsrs/{version}"),
        is_fallback: false,
        files: vec!["API.md".to_string()],
        ai_notes: crate_config.ai_notes.clone(),
    };

    let provenance = latest_docs_summary_provenance("docsrs", docsrs_input_url, truncated);
    fs::write(
        crate_dir.join("_SUMMARY.md"),
        render_summary_with_provenance(&saved, Some(&provenance)),
    )?;
    Ok(saved)
}

pub struct SaveContext<'a> {
    pub repo: &'a str,
    pub resolved: &'a ResolvedRef,
    pub max_file_size_kb: usize,
    pub source_kind: &'a str,
    pub artifact_path: Option<&'a str>,
    pub docsrs_input_url: Option<&'a str>,
    pub upstream_latest_version: Option<&'a str>,
    pub truncated: Option<bool>,
}

pub fn read_meta(output_dir: &Path, crate_name: &str, version: &str) -> Option<CrateMeta> {
    let crate_dir = output_dir.join(format!("{crate_name}@{version}"));
    let meta_path = crate_dir.join(".aifd-meta.toml");
    load_meta_with_migration(&meta_path)
}

pub fn read_cached_info(
    output_dir: &Path,
    crate_name: &str,
    version: &str,
    crate_config: &CrateDoc,
) -> Option<SavedCrate> {
    let crate_dir = output_dir.join(format!("{crate_name}@{version}"));
    let meta_path = crate_dir.join(".aifd-meta.toml");
    let meta = load_meta_with_migration(&meta_path)?;

    let mut files: Vec<String> = fs::read_dir(&crate_dir)
        .ok()?
        .filter_map(std::result::Result::ok)
        .filter_map(|e| {
            let name = e.file_name().to_str()?.to_string();
            if name.starts_with('.') || name == "_SUMMARY.md" {
                None
            } else {
                Some(name)
            }
        })
        .collect();
    files.sort();

    Some(SavedCrate {
        name: crate_name.to_string(),
        version: version.to_string(),
        git_ref: meta.git_ref,
        is_fallback: meta.is_fallback,
        files,
        ai_notes: crate_config.ai_notes.clone(),
    })
}

pub fn prune(
    output_dir: &Path,
    config: &Config,
    lock_versions: &HashMap<String, String>,
) -> Result<()> {
    if !output_dir.exists() {
        return Ok(());
    }

    let configured: HashSet<&str> = config.crates.keys().map(String::as_str).collect();

    for entry in fs::read_dir(output_dir)? {
        let entry = entry?;
        let path = entry.path();

        if !path.is_dir() {
            continue;
        }

        let Some(dir_name) = path.file_name().and_then(|n| n.to_str()) else {
            continue;
        };

        let Some((crate_name, dir_version)) = split_name_version(dir_name) else {
            continue;
        };

        let should_remove = if configured.contains(crate_name) {
            lock_versions
                .get(crate_name)
                .is_none_or(|lock_ver| lock_ver != dir_version)
        } else {
            true
        };

        if should_remove {
            info!("  ðŸ—‘ Pruning {dir_name}");
            fs::remove_dir_all(path)?;
        }
    }

    Ok(())
}

fn split_name_version(dir_name: &str) -> Option<(&str, &str)> {
    let (name, version) = dir_name.rsplit_once('@')?;
    if name.is_empty() || version.is_empty() {
        return None;
    }
    Some((name, version))
}

pub fn rust_output_dir(base_output_dir: &Path) -> PathBuf {
    if base_output_dir.file_name().and_then(|n| n.to_str()) == Some("rust") {
        return base_output_dir.to_path_buf();
    }
    base_output_dir.join("rust")
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::config::CrateDoc;

    #[test]
    fn test_flatten_root_file() {
        assert_eq!(flatten_filename("README.md"), "README.md");
    }

    #[test]
    fn test_flatten_nested_file() {
        assert_eq!(
            flatten_filename("docs/guides/overview.md"),
            "docs__guides__overview.md"
        );
    }

    #[test]
    fn test_should_inject_header() {
        assert!(should_inject_header("README.md"));
        assert!(should_inject_header("guide.html"));
        assert!(!should_inject_header("example.rs"));
    }

    #[test]
    fn test_truncate_large_file() {
        let content = "x".repeat(300 * 1024);
        let result = truncate_if_needed(&content, 200);
        assert!(result.contains("[TRUNCATED by ai-fdocs at 200KB]"));
    }

    #[test]
    fn test_split_name_version() {
        assert_eq!(split_name_version("serde@1.0.0"), Some(("serde", "1.0.0")));
        assert_eq!(split_name_version("serde"), None);
    }

    #[test]
    fn test_config_fingerprint_changes_when_repo_changes() {
        let mut cfg = CrateDoc {
            repo: Some("serde-rs/serde".to_string()),
            subpath: None,
            files: None,
            sources: None,
            ai_notes: String::new(),
        };

        let fp1 = crate_config_fingerprint(&cfg);
        cfg.repo = Some("tokio-rs/tokio".to_string());
        let fp2 = crate_config_fingerprint(&cfg);

        assert_ne!(fp1, fp2);
    }

    #[test]
    fn test_latest_docs_summary_provenance_includes_source_and_truncation() {
        let p = latest_docs_summary_provenance("docsrs", "https://docs.rs/crate/serde/1.0.0", true);
        assert!(p.contains("Source kind: `docsrs`"));
        assert!(p.contains("Truncated: `true`"));
    }

    #[test]
    fn test_render_summary_contains_file_links() {
        let saved = SavedCrate {
            name: "serde".to_string(),
            version: "1.0.0".to_string(),
            git_ref: "v1.0.0".to_string(),
            is_fallback: false,
            files: vec!["README.md".to_string(), "CHANGELOG.md".to_string()],
            ai_notes: "Use derive macros".to_string(),
        };

        let summary = render_crate_summary(&saved);
        assert!(summary.contains("# serde@1.0.0"));
        assert!(summary.contains("## AI Notes"));
        assert!(summary.contains("[README.md](README.md)"));
    }
    #[test]
    fn test_load_meta_migrates_legacy_schema() {
        let tmp =
            std::env::temp_dir().join(format!("ai-fdocs-meta-migrate-{}", std::process::id()));
        let _ = fs::remove_dir_all(&tmp);
        fs::create_dir_all(&tmp).expect("create temp dir");
        let meta_path = tmp.join(".aifd-meta.toml");

        let legacy = r#"version = "1.0.0"
git_ref = "v1.0.0"
fetched_at = "2026-01-01"
is_fallback = false
config_fingerprint = "abc"
"#;
        fs::write(&meta_path, legacy).expect("write legacy meta");

        let migrated = load_meta_with_migration(&meta_path).expect("load migrated");
        assert_eq!(migrated.schema_version, META_SCHEMA_VERSION);

        let rewritten = fs::read_to_string(&meta_path).expect("read rewritten meta");
        assert!(rewritten.contains("schema_version = 1"));

        let _ = fs::remove_dir_all(&tmp);
    }

    #[test]
    fn test_load_meta_rejects_newer_schema() {
        let tmp = std::env::temp_dir().join(format!("ai-fdocs-meta-newer-{}", std::process::id()));
        let _ = fs::remove_dir_all(&tmp);
        fs::create_dir_all(&tmp).expect("create temp dir");
        let meta_path = tmp.join(".aifd-meta.toml");

        let newer = r#"schema_version = 99
version = "1.0.0"
git_ref = "v1.0.0"
fetched_at = "2026-01-01"
is_fallback = false
config_fingerprint = "abc"
"#;
        fs::write(&meta_path, newer).expect("write newer meta");

        assert!(load_meta_with_migration(&meta_path).is_none());

        let _ = fs::remove_dir_all(&tmp);
    }
}
